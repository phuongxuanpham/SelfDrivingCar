{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Project 3 in Self Driving Car Nano degree from Udacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Cloning Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "- Use the simulator to collect data of good driving behavior\n",
    "- Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "- Train and validate the model with a training and validation set\n",
    "- Test that the model successfully drives around track one without leaving the road\n",
    "- Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric Points\n",
    "\n",
    "Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files Submitted & Code Quality\n",
    "\n",
    "#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "My project includes the following files:\n",
    "\n",
    "    model.ipynb containing the script to create and train the model\n",
    "    drive.py for driving the car in autonomous mode\n",
    "    model.h5 containing a trained convolution neural network\n",
    "    writeup_report.md or writeup_report.pdf summarizing the results\n",
    "#### 2. Submission includes functional code Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing\n",
    "\n",
    "    python drive.py model.h5\n",
    "#### 3. Submission code is usable and readable\n",
    "\n",
    "The model.ipynb file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. An appropriate model architecture has been employed\n",
    "\n",
    "My model is based on model proposed by the NVIDIA in [this paper](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf). The NVIDIA model is well-documented and not complicated and has been proven its effectiveness in self driving car control.\n",
    "\n",
    "The model architecture is summarized as follows:\n",
    "\n",
    "Layer        | Description\n",
    "------------ | -------------\n",
    "Input\t| 66x200x3 RGB image\n",
    "Lambda | Normalized\n",
    "Convolution 5x5x24 | valid padding, subsample(2,2), activation ReLU, outputs 31x98x24\n",
    "Convolution 5x5x36 | valid padding, subsample(2,2), activation ReLU, outputs 14x47x36\n",
    "Convolution 5x5x48 | valid padding, subsample(2,2), activation ReLU, outputs 5x22x48\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 3x20x64\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 1x18x64\n",
    "Flatten | outputs 1152\n",
    "Fully connected\t| activation ReLU, outputs 100\n",
    "Fully connected\t| activation ReLU, outputs 50\n",
    "Fully connected\t| activation ReLU, outputs 20\n",
    "Fully connected\t| outputs 1\n",
    "\n",
    "My model consists of a convolution neural network with three 5x5 and 3x3  filter sizes and depths between 24 and 64.\n",
    "\n",
    "The convolution layers includes RELU activations to introduce nonlinearity and downsample 2 times.\n",
    "\n",
    "The data is normalized in the model using a Keras lambda layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Attempts to reduce overfitting in the model\n",
    "\n",
    "The model contains a dropout layer with keeping probability 0.5  in order to reduce overfitting.\n",
    "\n",
    "The model was trained and validated on different data sets to ensure that the model was not overfitting. The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model parameter tuning\n",
    "\n",
    "The model used an adam optimizer, so the learning rate was not tuned manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Appropriate training data\n",
    "\n",
    "Training data was chosen to keep the vehicle driving on the road. I used a combination of \n",
    "- center lane driving, \n",
    "- recovering from the left and right sides of the road, \n",
    "- driving counter-clockwise to help the model generalized, \n",
    "- flipping the images to help the model generalized, \n",
    "- collecting data from the second track can also help generalize the model\n",
    "\n",
    "For details about how I created the training data, see the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture and Training Documentation\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "\n",
    "The overall strategy for deriving a model architecture was to use a well-known model that is sucessful in the field of self driving car and then twist model parameters as well as use appropriate image pre-processing and augmentation to the training dataset. The model was trained and validated on different data sets to ensure that the model was not overfitting. The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.\n",
    "\n",
    "My first step was to use a convolution neural network model similar to the NVIDIA model in [this paper](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf). I thought this model might be appropriate because the NVIDIA model is well-documented and not complicated and has been proven its effectiveness in self driving car control.\n",
    "\n",
    "Then I focused on image pre-processing methods which including: \n",
    "- Crop the sky and steering wheel parts in the image.\n",
    "- Resize the images from 160x320x3 matrix to 60x200x3 matrix, which is the input size of the NVIDIA model.\n",
    "\n",
    "In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set. I found that my first model had a low mean squared error on the training set but a high mean squared error on the validation set. This implied that the model was overfitting.\n",
    "\n",
    "To combat the overfitting, I modified the model so that the model contains a dropout layer with keeping probability 0.5 in order to reduce overfitting.\n",
    "\n",
    "The final step was to run the simulator to see how well the car was driving around track one. \n",
    "\n",
    "There were a few spots where the vehicle fell off the track. To improve the driving behavior in these cases, I collected more training data in the track one, track two as well as generate more training data using image augmentation methods (see details in the next part).\n",
    "\n",
    "At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Final Model Architecture\n",
    "\n",
    "The final model architecture consisted of a convolution neural network with the following layers and layer sizes.\n",
    "\n",
    "Layer        | Description\n",
    "------------ | -------------\n",
    "Input\t| 66x200x3 RGB image\n",
    "Lambda | Normalized\n",
    "Convolution 5x5x24 | valid padding, subsample(2,2), activation ReLU, outputs 31x98x24\n",
    "Convolution 5x5x36 | valid padding, subsample(2,2), activation ReLU, outputs 14x47x36\n",
    "Convolution 5x5x48 | valid padding, subsample(2,2), activation ReLU, outputs 5x22x48\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 3x20x64\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 1x18x64\n",
    "Dropout | keeping probability 0.5\n",
    "Flatten | outputs 1152\n",
    "Fully connected\t| activation ReLU, outputs 100\n",
    "Fully connected\t| activation ReLU, outputs 50\n",
    "Fully connected\t| activation ReLU, outputs 20\n",
    "Fully connected\t| outputs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Creation of the Training Set & Training Process\n",
    "\n",
    "To capture good driving behavior, I first recorded two laps on track one using center lane driving. Here is an example image of center lane driving on track one:\n",
    "\n",
    "![title](images/center_1.jpg)\n",
    "\n",
    "I then recorded the vehicle recovering from the left side and right sides of the road back to center so that the vehicle would learn how to go back the center of driving from the left side and right sides. These images show what a recovery looks like:\n",
    "\n",
    "![title](images/side_1.jpg)\n",
    "![title](images/side_2.jpg)\n",
    "![title](images/side_3.jpg)\n",
    "\n",
    "To augment the data sat, I also randomly flipped images and angles thinking that this would balance the left turn bias because the tracks are left-turn. For example, here is an image that has then been flipped:\n",
    "\n",
    "![title](images/center_1.jpg)\n",
    "![title](images/center_1_flipped.jpg)\n",
    "\n",
    "I also recorded the vehicle running around the curves only so that the vehicle would learn how to go around the curves.\n",
    "\n",
    "The simulator captures images from three cameras mounted on the car: a center, right and left camera. Thatâ€™s because of the issue of recovering from being off-center.\n",
    "\n",
    "I also recorded the counter-clockwise driving on track one and track two for better model generalization.\n",
    "\n",
    "After the collection process, I had X number of data points. I then preprocessed this data by cropping the sky and steering wheel parts in the images and resizing the images to the size of 66 pixel height x 200 pixel width to match with the required input shape of the model.\n",
    "\n",
    "I finally randomly shuffled the data set and put 20% of the data into a validation set.\n",
    "\n",
    "I used this training data for training the model. The validation set helped determine if the model was over or under fitting. The ideal number of epochs was Z as evidenced by ... I used an adam optimizer so that manually training the learning rate wasn't necessary.\n",
    "\n",
    "\n",
    "\n",
    "Then I repeated this process on track two in order to get more data points.\n",
    "\n",
    "Here is an example image of center lane driving on track two:\n",
    "\n",
    "alt text\n",
    "\n",
    "Here is an example image of vehicle recovering from the left side and right sides of the road back to center on track two:\n",
    "\n",
    "alt text alt text alt text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_image(img, angle):\n",
    "    \"\"\"\n",
    "    Randomly flip the image and adjust the steering angle.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "        angle = -angle\n",
    "    return img, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the driving_log.csv and get paths of images as samples\n",
    "samples = []\n",
    "with open('../../P3_Data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using generator function to compile and train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32, is_training=False):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = '../../P3_Data/IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # Get training data\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            \n",
    "            # Randomly flip image if in training mode\n",
    "            if is_training == True:\n",
    "                X_train_augmented, y_train_augmented = [], []\n",
    "                for x, y in zip(X_train, y_train):\n",
    "                    x_augmented, y_augmented = flip_image(x, y)\n",
    "                    X_train_augmented.append(x_augmented)\n",
    "                    y_train_augmented.append(y_augmented)\n",
    "\n",
    "                X_train_augmented = np.array(X_train_augmented)\n",
    "                y_train_augmented = np.array(y_train_augmented)\n",
    "                #print(X_train_augmented.shape)\n",
    "\n",
    "                yield sklearn.utils.shuffle(X_train_augmented, y_train_augmented)\n",
    "            \n",
    "            else:\n",
    "                yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32, is_training=True)\n",
    "validation_generator = generator(validation_samples, batch_size=32, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "cropping2d_3 (Cropping2D)        (None, 75, 320, 3)    0           cropping2d_input_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                (None, 66, 200, 3)    0           cropping2d_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                (None, 66, 200, 3)    0           lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 31, 98, 24)    1824        lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 14, 47, 36)    21636       convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 5, 22, 48)     43248       convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 3, 20, 64)     27712       convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 1, 18, 64)     36928       convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 1, 18, 64)     0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 1152)          0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 100)           115300      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 50)            5050        dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 10)            510         dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1)             11          dense_11[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phuongpham/anaconda3/anaconda/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1917: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "3906/3906 [==============================] - 32s - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 2/5\n",
      "3906/3906 [==============================] - 31s - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 3/5\n",
      "3906/3906 [==============================] - 32s - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 4/5\n",
      "3906/3906 [==============================] - 32s - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 5/5\n",
      "3906/3906 [==============================] - 33s - loss: 0.0080 - val_loss: 0.0072\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEklSi0EiSWoxSCRJLT9BQu7PQH0b+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1263004e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build network architecture \n",
    "# for a regression network (need only 1 neuron at output)\n",
    "from keras.models import Sequential, Model\n",
    "#from keras.layers import Lambda, Cropping2D\n",
    "from keras.layers.core import Flatten, Dense, Activation, Dropout, Lambda\n",
    "from keras.activations import relu \n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.backend import tf as ktf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "row, col, ch = 160, 320, 3  # image format\n",
    "INPUT_SHAPE = (row,col,ch)\n",
    "\n",
    "def resize(image):\n",
    "    from keras.backend import tf as ktf   \n",
    "    resized = ktf.image.resize_images(image, (66, 200))\n",
    "    return resized\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "## Set up lambda layers for data preprocessing: \n",
    "\n",
    "# Set up cropping2D layer: cropping (top, bottom) (left, right) pixels \n",
    "model.add(Cropping2D(cropping=((60,25), (0,0)), input_shape=INPUT_SHAPE)) \n",
    "\n",
    "# Add Lambda layer for resizing image (image, height, width, data_format)\n",
    "# model.add(Lambda(lambda x: ktf.image.resize_images(x, new_shape)))\n",
    "model.add(Lambda(resize, input_shape=(75, 320, 3), output_shape=(66, 200, 3)))\n",
    "\n",
    "# Add Lambda layer for normalization\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0))\n",
    "\n",
    "## Build a Multi-layer feedforward neural network with Keras here.\n",
    "\n",
    "# 1st Layer - Add a convolution layer\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))\n",
    "\n",
    "# 2nd Layer - Add a convolution layer\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))\n",
    "\n",
    "# 3rd Layer - Add a convolution layer\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))\n",
    "\n",
    "# 4th Layer - Add a convolution layer\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "\n",
    "# 5th Layer - Add a convolution layer\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "\n",
    "# 6th Layer - Add a convolution layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 7th Layer - Add a flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 8th Layer - Add a fully connected layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "# 9th Layer - Add a fully connected layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# 10th Layer - Add a fully connected layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# 11th Layer - Add a fully connected layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# saves the model weights after each epoch if the validation loss decreased\n",
    "checkpointer = ModelCheckpoint('model-{epoch:02d}.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mse', verbose = 1)\n",
    "# history_object = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=7, batch_size=128)\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch=len(train_samples), \\\n",
    "                                     validation_data=validation_generator, nb_val_samples=len(validation_samples), \\\n",
    "                                     nb_epoch=10, callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "#model.save('model.h5')\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the network\n",
    "\n",
    "I run the network on the pre-trained model with the following command:\n",
    "\n",
    "    python drive.py model.h5\n",
    "    \n",
    "And run the simulator with the Autonomous mode. The output video was recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to the output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
